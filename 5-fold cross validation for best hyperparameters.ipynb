{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d63170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "input_json_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\Training ML\\train_after_correlationandPCA.json'\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "data = pd.read_json(input_json_path, orient='records', lines=True)\n",
    "\n",
    "# adjust display settings to show all columns\n",
    "with pd.option_context('display.max_columns', None, 'display.max_rows', None):\n",
    "    print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of additional categorical columns that need to be encoded\n",
    "additional_categorical_columns = ['byg056Varmeinstallation', 'eta006BygningensEtagebetegnelse', \n",
    "                                  'landscape', 'TSYM', 'byg021BygningensAnvendelse_grouped']\n",
    "\n",
    "# Perform one-hot encoding for the additional categorical columns\n",
    "data_encoded = pd.get_dummies(data, columns=additional_categorical_columns)\n",
    "\n",
    "# Display the first few rows of the encoded DataFrame\n",
    "with pd.option_context('display.max_columns', None, 'display.max_rows', None):\n",
    "    print(data_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of original features from the importance list\n",
    "original_features = [\n",
    "    'Damage', 'areasqm_2', 'middelvind', 'b_div_c', 'eta020SamletArealAfEtage', 'height_mea_2',\n",
    "    'frostdoegn', 'dagligmaxt', 'doegn2aars', 'byg026Opførelsesår', 'coast',\n",
    "    'clay_depth', 'dtm20', 'bluespot', 'slope20', 'waterbodies',\n",
    "    'groundwate', 'landmovelandmove_idw25', 'sand_depth'\n",
    "]\n",
    "\n",
    "# List of one-hot encoded categorical features from the importance list\n",
    "encoded_categorical_features = [\n",
    "    'byg056Varmeinstallation_9', 'byg021BygningensAnvendelse_grouped_99', \n",
    "    'byg056Varmeinstallation_1', 'byg021BygningensAnvendelse_grouped_14', 'eta006BygningensEtagebetegnelse_1', \n",
    "    'landscape_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Combine the lists\n",
    "all_relevant_features = original_features + encoded_categorical_features\n",
    "\n",
    "# Filter the data_encoded DataFrame to keep only the relevant columns\n",
    "data_encoded_filtered = data_encoded[all_relevant_features]\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "with pd.option_context('display.max_columns', None, 'display.max_rows', None):\n",
    "    print(data_encoded_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = data_encoded_filtered.drop(columns=['Damage'])\n",
    "y = data_encoded_filtered['Damage']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "# Keeping 30% of the data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# The variables X_train, X_test, y_train, y_test are  ready for use in model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following part is a selection of scripts for each model's cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ad7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specified parameters for Random Forest\n",
    "n_estimators = 200\n",
    "max_depth = 60\n",
    "min_samples_split = 4\n",
    "min_samples_leaf = 1\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Convert y_train to a numpy array\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Initialize and configure the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    random_state=None\n",
    ")\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store the metrics for each class and overall accuracy\n",
    "metrics_class_0 = {'precision': [], 'recall': [], 'f1-score': [], 'support': []}\n",
    "metrics_class_1 = {'precision': [], 'recall': [], 'f1-score': [], 'support': []}\n",
    "overall_accuracy = []\n",
    "pr_aucs = []\n",
    "roc_aucs = []\n",
    " \n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    # Split data into training and test sets\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    rf_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test_fold)\n",
    "    y_probs = rf_model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "    # Compute classification report\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True)\n",
    "\n",
    "    # Extract metrics for each class\n",
    "    metrics_class_0['precision'].append(report['0']['precision'])\n",
    "    metrics_class_0['recall'].append(report['0']['recall'])\n",
    "    metrics_class_0['f1-score'].append(report['0']['f1-score'])\n",
    "    metrics_class_0['support'].append(report['0']['support'])\n",
    "\n",
    "    metrics_class_1['precision'].append(report['1']['precision'])\n",
    "    metrics_class_1['recall'].append(report['1']['recall'])\n",
    "    metrics_class_1['f1-score'].append(report['1']['f1-score'])\n",
    "    metrics_class_1['support'].append(report['1']['support'])\n",
    "\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "    # PR and ROC curves\n",
    "    precision, recall, _ = precision_recall_curve(y_test_fold, y_probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    fpr, tpr, _ = roc_curve(y_test_fold, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    pr_aucs.append(pr_auc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    # Plot the Precision-Recall curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "# Calculate average metrics for each class\n",
    "avg_metrics_class_0 = {metric: np.mean(values) for metric, values in metrics_class_0.items()}\n",
    "avg_metrics_class_1 = {metric: np.mean(values) for metric, values in metrics_class_1.items()}\n",
    "avg_accuracy = np.mean(overall_accuracy)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Class 0 - Precision: {avg_metrics_class_0['precision']}, Recall: {avg_metrics_class_0['recall']}, F1-score: {avg_metrics_class_0['f1-score']}\")\n",
    "print(f\"Class 1 - Precision: {avg_metrics_class_1['precision']}, Recall: {avg_metrics_class_1['recall']}, F1-score: {avg_metrics_class_1['f1-score']}\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n",
    "# Print average PR AUC and ROC AUC\n",
    "print(f\"Average PR AUC Across All Folds: {np.mean(pr_aucs)}\")\n",
    "print(f\"Average ROC AUC Across All Folds: {np.mean(roc_aucs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d11fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked Generalization\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Base learners with specific configurations\n",
    "base_learners = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=60, min_samples_split=4, min_samples_leaf=1)),\n",
    "    ('lgbm', lgb.LGBMClassifier(n_estimators=250, learning_rate=0.15, max_depth=9, num_leaves=100)),\n",
    "    ('gnb', GaussianNB())\n",
    "]\n",
    "\n",
    "# Final estimator\n",
    "final_estimator = RidgeClassifier()\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Initialize and configure the Stacking model\n",
    "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=final_estimator, cv=10)\n",
    "\n",
    "# Lists to store metrics\n",
    "metrics_class_0 = {'precision': [], 'recall': [], 'f1-score': [], 'support': []}\n",
    "metrics_class_1 = {'precision': [], 'recall': [], 'f1-score': [], 'support': []}\n",
    "overall_accuracy = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    stacking_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = stacking_model.predict(X_test_fold)\n",
    "\n",
    "    # Compute classification report\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True)\n",
    "\n",
    "    # Extract metrics for each class\n",
    "    for class_label in ['0', '1']:\n",
    "        metrics_class_0['precision'].append(report[class_label]['precision'])\n",
    "        metrics_class_0['recall'].append(report[class_label]['recall'])\n",
    "        metrics_class_0['f1-score'].append(report[class_label]['f1-score'])\n",
    "        metrics_class_0['support'].append(report[class_label]['support'])\n",
    "\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "# Calculate average metrics for each class\n",
    "avg_metrics_class_0 = {metric: np.mean(values) for metric, values in metrics_class_0.items()}\n",
    "avg_metrics_class_1 = {metric: np.mean(values) for metric, values in metrics_class_1.items()}\n",
    "avg_accuracy = np.mean(overall_accuracy)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Class 0 - Precision: {avg_metrics_class_0['precision']}, Recall: {avg_metrics_class_0['recall']}, F1-score: {avg_metrics_class_0['f1-score']}\")\n",
    "print(f\"Class 1 - Precision: {avg_metrics_class_1['precision']}, Recall: {avg_metrics_class_1['recall']}, F1-score: {avg_metrics_class_1['f1-score']}\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59671b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Specified parameters for AdaBoost\n",
    "base_depth = 6\n",
    "n_estimators = 200\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Initialize the base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(max_depth=base_depth)\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "metrics_class_0 = {'precision': [], 'recall': [], 'f1-score': []}\n",
    "metrics_class_1 = {'precision': [], 'recall': [], 'f1-score': []}\n",
    "overall_accuracy = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Initialize and configure the AdaBoost model\n",
    "    ada_model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "    # Fit the model\n",
    "    ada_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = ada_model.predict(X_test_fold)\n",
    "\n",
    "    # Compute classification report\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    # Extract metrics for each class\n",
    "    for class_label in ['0', '1']:\n",
    "        if class_label in report:\n",
    "            metrics_class_0['precision'].append(report[class_label]['precision'])\n",
    "            metrics_class_0['recall'].append(report[class_label]['recall'])\n",
    "            metrics_class_0['f1-score'].append(report[class_label]['f1-score'])\n",
    "        else:\n",
    "            metrics_class_0['precision'].append(np.nan)\n",
    "            metrics_class_0['recall'].append(np.nan)\n",
    "            metrics_class_0['f1-score'].append(np.nan)\n",
    "\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "# Calculate average metrics for each class\n",
    "avg_metrics_class_0 = {metric: np.nanmean(values) for metric, values in metrics_class_0.items()}\n",
    "avg_metrics_class_1 = {metric: np.nanmean(values) for metric, values in metrics_class_1.items()}\n",
    "avg_accuracy = np.nanmean(overall_accuracy)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Class 0 - Precision: {avg_metrics_class_0['precision']}, Recall: {avg_metrics_class_0['recall']}, F1-score: {avg_metrics_class_0['f1-score']}\")\n",
    "print(f\"Class 1 - Precision: {avg_metrics_class_1['precision']}, Recall: {avg_metrics_class_1['recall']}, F1-score: {avg_metrics_class_1['f1-score']}\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Specified parameters for Gradient Boosting\n",
    "n_estimators = 900\n",
    "learning_rate = 0.07333333333333333\n",
    "max_depth = 8\n",
    "min_samples_split = 10\n",
    "min_samples_leaf = 5\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Convert y_train to a numpy array\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Initialize and configure the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    random_state=None\n",
    ")\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store the metrics for each class\n",
    "metrics_class_0 = {'precision': [], 'recall': [], 'f1-score': [], 'support': []}\n",
    "metrics_class_1 = {'precision': [], 'recall': [], 'f1-score': [], 'support': []}\n",
    "overall_accuracy = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    # Split data into training and test sets\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Fit the model\n",
    "    gb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = gb_model.predict(X_test_fold)\n",
    "\n",
    "    # Compute classification report\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True)\n",
    "\n",
    "    # Extract metrics for each class\n",
    "    metrics_class_0['precision'].append(report['0']['precision'])\n",
    "    metrics_class_0['recall'].append(report['0']['recall'])\n",
    "    metrics_class_0['f1-score'].append(report['0']['f1-score'])\n",
    "    metrics_class_0['support'].append(report['0']['support'])\n",
    "\n",
    "    metrics_class_1['precision'].append(report['1']['precision'])\n",
    "    metrics_class_1['recall'].append(report['1']['recall'])\n",
    "    metrics_class_1['f1-score'].append(report['1']['f1-score'])\n",
    "    metrics_class_1['support'].append(report['1']['support'])\n",
    "\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "# Calculate average metrics for each class\n",
    "avg_metrics_class_0 = {metric: np.mean(values) for metric, values in metrics_class_0.items()}\n",
    "avg_metrics_class_1 = {metric: np.mean(values) for metric, values in metrics_class_1.items()}\n",
    "avg_accuracy = np.mean(overall_accuracy)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Class 0 - Precision: {avg_metrics_class_0['precision']}, Recall: {avg_metrics_class_0['recall']}, F1-score: {avg_metrics_class_0['f1-score']}\")\n",
    "print(f\"Class 1 - Precision: {avg_metrics_class_1['precision']}, Recall: {avg_metrics_class_1['recall']}, F1-score: {avg_metrics_class_1['f1-score']}\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd2696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Specified parameters for ANN\n",
    "layers = (128,)\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train to a numpy array\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics and AUCs\n",
    "overall_accuracy = []\n",
    "pr_aucs = []\n",
    "roc_aucs = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    # Split data into training and test sets\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = Sequential()\n",
    "    for layer_size in layers:\n",
    "        model.add(Dense(layer_size, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_probs = model.predict(X_test_fold).ravel()\n",
    "    y_pred = (y_probs > 0.5).astype(int)\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True)\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "    # PR and ROC curves\n",
    "    precision, recall, _ = precision_recall_curve(y_test_fold, y_probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    fpr, tpr, _ = roc_curve(y_test_fold, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    pr_aucs.append(pr_auc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    # Plot the Precision-Recall curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Calculate average accuracy and AUC\n",
    "avg_accuracy = np.mean(overall_accuracy)\n",
    "avg_pr_auc = np.mean(pr_aucs)\n",
    "avg_roc_auc = np.mean(roc_aucs)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n",
    "print(f\"Average PR AUC Across All Folds: {avg_pr_auc}\")\n",
    "print(f\"Average ROC AUC Across All Folds: {avg_roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f3d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost parameters\n",
    "params = {\n",
    "    'n_estimators': 800,\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 2,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.1,\n",
    "    'gamma': 0.2,\n",
    "    'min_child_weight': 6,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.2\n",
    "}\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train to a numpy array\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics and AUCs\n",
    "overall_accuracy = []\n",
    "pr_aucs = []\n",
    "roc_aucs = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    # Split data into training and test sets\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Create and train the XGBoost model\n",
    "    xgb_model = xgb.XGBClassifier(**params)\n",
    "    xgb_model.fit(X_train_fold, y_train_fold, eval_metric='logloss')\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb_model.predict(X_test_fold)\n",
    "    y_probs = xgb_model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "    # Compute classification report and update metrics\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True)\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "    # PR and ROC curves\n",
    "    precision, recall, _ = precision_recall_curve(y_test_fold, y_probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    fpr, tpr, _ = roc_curve(y_test_fold, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    pr_aucs.append(pr_auc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    # Plot the Precision-Recall curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Calculate average accuracy and AUC\n",
    "avg_accuracy = np.mean(overall_accuracy)\n",
    "avg_pr_auc = np.mean(pr_aucs)\n",
    "avg_roc_auc = np.mean(roc_aucs)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n",
    "print(f\"Average PR AUC Across All Folds: {avg_pr_auc}\")\n",
    "print(f\"Average ROC AUC Across All Folds: {avg_roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "    'n_estimators': 250,\n",
    "    'learning_rate': 0.15,\n",
    "    'max_depth': 9,\n",
    "    'num_leaves': 100\n",
    "}\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train to a numpy array\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics and AUCs\n",
    "overall_accuracy = []\n",
    "pr_aucs = []\n",
    "roc_aucs = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    # Split data into training and test sets\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Create and train the LightGBM model\n",
    "    lgb_model = lgb.LGBMClassifier(**params)\n",
    "    lgb_model.fit(X_train_fold, y_train_fold, eval_metric='logloss')\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = lgb_model.predict(X_test_fold)\n",
    "    y_probs = lgb_model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "    # Compute classification report and update metrics\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True)\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "    # PR and ROC curves\n",
    "    precision, recall, _ = precision_recall_curve(y_test_fold, y_probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    fpr, tpr, _ = roc_curve(y_test_fold, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    pr_aucs.append(pr_auc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    # Plot the Precision-Recall curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Calculate average accuracy and AUC\n",
    "avg_accuracy = np.mean(overall_accuracy)\n",
    "avg_pr_auc = np.mean(pr_aucs)\n",
    "avg_roc_auc = np.mean(roc_aucs)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n",
    "print(f\"Average PR AUC Across All Folds: {avg_pr_auc}\")\n",
    "print(f\"Average ROC AUC Across All Folds: {avg_roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295be16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Best Gaussian Naive Bayes parameter\n",
    "var_smoothing = 5.455594781168514e-06\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train to a numpy array\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics and AUCs\n",
    "overall_accuracy = []\n",
    "pr_aucs = []\n",
    "roc_aucs = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    # Split data into training and test sets\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Create and train the Gaussian Naive Bayes model\n",
    "    gnb_model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    gnb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = gnb_model.predict(X_test_fold)\n",
    "    y_probs = gnb_model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "    # Compute classification report and update metrics\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True)\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "    # PR and ROC curves\n",
    "    precision, recall, _ = precision_recall_curve(y_test_fold, y_probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    fpr, tpr, _ = roc_curve(y_test_fold, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    pr_aucs.append(pr_auc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    # Plot the Precision-Recall curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Calculate average accuracy and AUC\n",
    "avg_accuracy = np.mean(overall_accuracy)\n",
    "avg_pr_auc = np.mean(pr_aucs)\n",
    "avg_roc_auc = np.mean(roc_aucs)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n",
    "print(f\"Average PR AUC Across All Folds: {avg_pr_auc}\")\n",
    "print(f\"Average ROC AUC Across All Folds: {avg_roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# KNN parameters\n",
    "n_neighbors = 7\n",
    "weights = 'distance'\n",
    "algorithm = 'ball_tree'\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train to a numpy array\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "# Define the k-fold cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics and AUCs\n",
    "overall_accuracy = []\n",
    "pr_aucs = []\n",
    "roc_aucs = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train_array)):\n",
    "    # Split data into training and test sets\n",
    "    X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_array[train_index], y_train_array[test_index]\n",
    "\n",
    "    # Create and train the KNN model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm)\n",
    "    knn_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = knn_model.predict(X_test_fold)\n",
    "    y_probs = knn_model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "    # Compute classification report and update metrics\n",
    "    report = classification_report(y_test_fold, y_pred, output_dict=True)\n",
    "    overall_accuracy.append(report['accuracy'])\n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Fold {i+1} Classification Report:\")\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_fold, y_pred)}\\n\")\n",
    "\n",
    "    # PR and ROC curves\n",
    "    precision, recall, _ = precision_recall_curve(y_test_fold, y_probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    fpr, tpr, _ = roc_curve(y_test_fold, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    pr_aucs.append(pr_auc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    # Plot the Precision-Recall curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(recall, precision, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for Fold {i+1}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Calculate average accuracy and AUC\n",
    "avg_accuracy = np.mean(overall_accuracy)\n",
    "avg_pr_auc = np.mean(pr_aucs)\n",
    "avg_roc_auc = np.mean(roc_aucs)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"Average Metrics Across All Folds:\")\n",
    "print(f\"Overall Accuracy: {avg_accuracy}\")\n",
    "print(f\"Average PR AUC Across All Folds: {avg_pr_auc}\")\n",
    "print(f\"Average ROC AUC Across All Folds: {avg_roc_auc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
