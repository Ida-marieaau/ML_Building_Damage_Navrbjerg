{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983d8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ijson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97376f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script that joins VUR to land parcels with 'samletFast': Samlet Fast Ejendom, SFE\n",
    "#Sums the ejendomværdibeløb and grundværdibeløb and counts how many times they were aggregated\n",
    "\n",
    "# Directories\n",
    "json_dir = r'D:\\FOLDER FROM THESIS\\THESIS\\Data\\VUR\\VUR_MUNI'\n",
    "shapefile_dir = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\Jordstykke_municipalities'\n",
    "output_dir = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\VUR_MAT_MUNI2'\n",
    "\n",
    "# Loop through each municipality\n",
    "for json_file in os.listdir(json_dir):\n",
    "    if not json_file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    kommune_code = json_file[:4]\n",
    "    shapefile_path = os.path.join(shapefile_dir, f\"{kommune_code}.shp\")\n",
    "\n",
    "    if not os.path.exists(shapefile_path):\n",
    "        print(f\"Skipping {kommune_code}: Shapefile not found.\")\n",
    "        continue\n",
    "\n",
    "    json_file_path = os.path.join(json_dir, json_file)\n",
    "    print(f\"Processing {kommune_code}\")\n",
    "\n",
    "    # Parsing JSON to create ejendomsvurdering_dict and property_dict\n",
    "    ejendomsvurdering_dict = {}\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        objects = ijson.items(f, 'item')\n",
    "        for entry in objects:\n",
    "            id_ = entry['id']\n",
    "            ejendomsvurdering_dict[id_] = {\n",
    "                'ejendomværdiBeløb': entry.get('ejendomværdiBeløb', entry.get('ejendomvÃ¦rdiBelÃ¸b', None)),\n",
    "                'grundværdiBeløb': entry.get('grundværdiBeløb', entry.get('grundvÃ¦rdiBelÃ¸b', None))\n",
    "            }\n",
    "\n",
    "    # Mapping BFEnummer to EjendomsvurderingID\n",
    "    property_dict = {}\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        objects = ijson.items(f, 'item')\n",
    "        for entry in objects:\n",
    "            id_ = entry['id']\n",
    "            for bfenummer_entry in entry.get(\"BFEnummerList\", []):\n",
    "                bfenummer = bfenummer_entry if isinstance(bfenummer_entry, int) else bfenummer_entry[\"BFEnummer\"]\n",
    "                property_dict.setdefault(bfenummer, {'ejendomværdiBeløb': 0, 'grundværdiBeløb': 0, 'count': 0})\n",
    "                property_dict[bfenummer]['ejendomværdiBeløb'] += ejendomsvurdering_dict.get(id_, {}).get('ejendomværdiBeløb', 0)\n",
    "                property_dict[bfenummer]['grundværdiBeløb'] += ejendomsvurdering_dict.get(id_, {}).get('grundværdiBeløb', 0)\n",
    "                property_dict[bfenummer]['count'] += 1  # Increment the count\n",
    "\n",
    "    print(\"Parsed JSON file\")\n",
    "\n",
    "    # Reading shapefile\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    print(\"Read shapefile\")\n",
    "\n",
    "    # Joining based on samletFast \n",
    "    gdf['samletFast'] = gdf['samletFast'].astype(int)\n",
    "    gdf['ejendomværdiBeløb'] = gdf['samletFast'].map(lambda x: property_dict.get(x, {}).get('ejendomværdiBeløb', None))\n",
    "    gdf['grundværdiBeløb'] = gdf['samletFast'].map(lambda x: property_dict.get(x, {}).get('grundværdiBeløb', None))\n",
    "    gdf['count'] = gdf['samletFast'].map(lambda x: property_dict.get(x, {}).get('count', 0))\n",
    "\n",
    "    # Rename the columns to be under 10 characters for shapefile compatibility\n",
    "    gdf.rename(columns={\n",
    "        'ejendomværdiBeløb': 'e_value',\n",
    "        'grundværdiBeløb': 'g_value'\n",
    "    }, inplace=True)\n",
    "\n",
    "    print(\"Joined data\")\n",
    "\n",
    "    # Writing to new shapefile\n",
    "    output_path = os.path.join(output_dir, f\"{kommune_code}.shp\")\n",
    "    gdf.to_file(output_path)\n",
    "    print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d5b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script that joins VUR to BPFG\n",
    "\n",
    "# Directories\n",
    "json_dir = r'D:\\FOLDER FROM THESIS\\THESIS\\Data\\VUR\\VUR_MUNI'\n",
    "shapefile_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Data\\Ejendom API\\BPFG\\BPFG.shp'\n",
    "output_dir = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\BPFG VUR'\n",
    "\n",
    "# Create output dir if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Initialize empty property_dict\n",
    "property_dict = {}\n",
    "\n",
    "# Loop through each municipality's JSON\n",
    "for json_file in os.listdir(json_dir):\n",
    "    if not json_file.endswith('.json'):\n",
    "        continue\n",
    "    \n",
    "    kommune_code = json_file[:4]\n",
    "    json_file_path = os.path.join(json_dir, json_file)\n",
    "    \n",
    "    print(f\"Processing JSON for {kommune_code}\")\n",
    "\n",
    "    # Parsing JSON to update property_dict\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        objects = ijson.items(f, 'item')\n",
    "        for entry in objects:\n",
    "            id_ = entry['id']\n",
    "            for bfenummer_entry in entry.get(\"BFEnummerList\", []):\n",
    "                bfenummer = bfenummer_entry if isinstance(bfenummer_entry, int) else bfenummer_entry[\"BFEnummer\"]\n",
    "                property_dict.setdefault(bfenummer, {'ejendomværdiBeløb': 0, 'grundværdiBeløb': 0})\n",
    "                property_dict[bfenummer]['ejendomværdiBeløb'] += entry.get('ejendomværdiBeløb', 0)\n",
    "                property_dict[bfenummer]['grundværdiBeløb'] += entry.get('grundværdiBeløb', 0)\n",
    "\n",
    "print(\"Finished processing all JSON files.\")\n",
    "\n",
    "# Reading the single BPFG shapefile\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "print(\"Read shapefile\")\n",
    "\n",
    "# Joining based on samletFast\n",
    "gdf['samletFast'] = gdf['samletFast'].apply(lambda x: int(x) if pd.notnull(x) else None)\n",
    "gdf['ejendomværdiBeløb'] = gdf['samletFast'].map(lambda x: property_dict.get(x, {}).get('ejendomværdiBeløb', None))\n",
    "gdf['grundværdiBeløb'] = gdf['samletFast'].map(lambda x: property_dict.get(x, {}).get('grundværdiBeløb', None))\n",
    "\n",
    "# Rename the columns for shapefile compatibility\n",
    "gdf.rename(columns={'ejendomværdiBeløb': 'e_value', 'grundværdiBeløb': 'g_value'}, inplace=True)\n",
    "\n",
    "print(\"Joined data\")\n",
    "\n",
    "# Writing to new shapefile\n",
    "output_path = os.path.join(output_dir, 'BPFG_with_VUR.shp')\n",
    "gdf.to_file(output_path)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40923dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script that joins VUR to Ejerlejlighed\n",
    "#The condominiums were polygons and the data was afterwards made into point centroids in QGIS\n",
    "\n",
    "# Directories\n",
    "json_dir = r'D:\\FOLDER FROM THESIS\\THESIS\\Data\\VUR\\VUR_MUNI'\n",
    "shapefile_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Data\\Ejendom API\\Ejerlejlighed\\Ejerlejlighed.shp'\n",
    "output_dir = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\Ejerlejlighed VUR'\n",
    "\n",
    "# Initialize empty property_dict\n",
    "property_dict = {}\n",
    "\n",
    "# Loop through each municipality's JSON\n",
    "for json_file in os.listdir(json_dir):\n",
    "    if not json_file.endswith('.json'):\n",
    "        continue\n",
    "    \n",
    "    kommune_code = json_file[:4]\n",
    "    json_file_path = os.path.join(json_dir, json_file)\n",
    "    \n",
    "    print(f\"Processing JSON for {kommune_code}\")\n",
    "\n",
    "    # Parsing JSON to update property_dict\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        objects = ijson.items(f, 'item')\n",
    "        for entry in objects:\n",
    "            id_ = entry['id']\n",
    "            for bfenummer_entry in entry.get(\"BFEnummerList\", []):\n",
    "                bfenummer = bfenummer_entry if isinstance(bfenummer_entry, int) else bfenummer_entry[\"BFEnummer\"]\n",
    "                property_dict.setdefault(bfenummer, {'ejendomværdiBeløb': 0, 'grundværdiBeløb': 0})\n",
    "                property_dict[bfenummer]['ejendomværdiBeløb'] += entry.get('ejendomværdiBeløb', 0)\n",
    "                property_dict[bfenummer]['grundværdiBeløb'] += entry.get('grundværdiBeløb', 0)\n",
    "\n",
    "print(\"Finished processing all JSON files.\")\n",
    "\n",
    "# Reading the single Ejerlejlighed shapefile\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "print(\"Read shapefile\")\n",
    "\n",
    "# Joining based on samletFast\n",
    "gdf['samletFast'] = gdf['samletFast'].apply(lambda x: int(x) if pd.notnull(x) else None)\n",
    "gdf['ejendomværdiBeløb'] = gdf['samletFast'].map(lambda x: property_dict.get(x, {}).get('ejendomværdiBeløb', None))\n",
    "gdf['grundværdiBeløb'] = gdf['samletFast'].map(lambda x: property_dict.get(x, {}).get('grundværdiBeløb', None))\n",
    "\n",
    "# Rename the columns for shapefile compatibility\n",
    "gdf.rename(columns={'ejendomværdiBeløb': 'e_value', 'grundværdiBeløb': 'g_value'}, inplace=True)\n",
    "\n",
    "print(\"Joined data\")\n",
    "\n",
    "# Writing to new shapefile\n",
    "output_path = os.path.join(output_dir, 'Ejerlejlighed_with_VUR.shp')\n",
    "gdf.to_file(output_path)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9da58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejerlejlighed and BPFG\n",
    "#Script that makes aggregated values for 'ejendomsværdibeløb' and 'grunværdibeløb' (within each land parcel) \n",
    "\n",
    "#Load the datasets\n",
    "polygon_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Data\\Matrikel\\Jordstykke\\MAT_jordstykke_DK.shp'\n",
    "point1_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\Ejerlejlighed VUR\\Ejerlejlighed_centroids_VUR.shp'\n",
    "point2_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\BPFG VUR\\BPFG_with_VUR.shp'\n",
    "\n",
    "polygon_gdf = gpd.read_file(polygon_path)\n",
    "point1_gdf = gpd.read_file(point1_path)\n",
    "point2_gdf = gpd.read_file(point2_path)\n",
    "\n",
    "# Generate spatial indices\n",
    "polygon_gdf.sindex\n",
    "point1_gdf.sindex\n",
    "point2_gdf.sindex\n",
    "\n",
    "# Perform spatial joins\n",
    "joined1 = sjoin(point1_gdf, polygon_gdf, how='inner', op='within')\n",
    "joined2 = sjoin(point2_gdf, polygon_gdf, how='inner', op='within')\n",
    "\n",
    "# Aggregate the data\n",
    "aggregated1 = joined1.groupby('index_right').agg({'e_value': 'sum', 'g_value': 'sum'})\n",
    "aggregated2 = joined2.groupby('index_right').agg({'e_value': 'sum', 'g_value': 'sum'})\n",
    "\n",
    "# Combine aggregated results\n",
    "combined_aggregated = aggregated1.add(aggregated2, fill_value=0)\n",
    "\n",
    "# Update the original polygon GeoDataFrame\n",
    "polygon_gdf['e_value'] = 0\n",
    "polygon_gdf['g_value'] = 0\n",
    "polygon_gdf.loc[combined_aggregated.index, 'e_value'] = combined_aggregated['e_value']\n",
    "polygon_gdf.loc[combined_aggregated.index, 'g_value'] = combined_aggregated['g_value']\n",
    "\n",
    "# Save the updated GeoDataFrame\n",
    "output_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\VUR_MAT_MUNI_ejerBPFG\\updated_MAT_jordstykke_DK2.shp'\n",
    "polygon_gdf.to_file(output_path)\n",
    "\n",
    "#A 'count' field of points within each polygon was created afterwards in QGIS (the file was named e_g_c_MAT_jordstykke_DK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating e_g_c_MAT_jordstykke_DK (BPFG and Ejerlejlighed) into municipalities\n",
    " \n",
    "# Load the jordstykke shapefile\n",
    "input_shapefile_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\VUR_MAT_MUNI_ejerBPFG\\e_g_c_MAT_jordstykke_DK.shp'\n",
    "gdf = gpd.read_file(input_shapefile_path)\n",
    "\n",
    "# Output directory\n",
    "output_dir = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\ejerBPFG_MUNI'\n",
    "\n",
    "# Get unique 'kommunekod' values\n",
    "unique_kommunekod = gdf['kommunekod'].unique()\n",
    "\n",
    "# Loop through each unique 'kommunekod' and save the subset as a new shapefile\n",
    "for k in unique_kommunekod:\n",
    "    subset_gdf = gdf[gdf['kommunekod'] == k]\n",
    "    output_path = os.path.join(output_dir, f\"{k}.shp\")\n",
    "    subset_gdf.to_file(output_path)\n",
    "    print(f\"Saved subset shapefile for kommunekod {k} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the land parcel data (MAT) into municipalities based on 'kommunekod'\n",
    "\n",
    "# Load the jordstykke shapefile\n",
    "jordstykke_path = 'D:\\\\FOLDER FROM THESIS\\\\THESIS\\\\Data\\\\Matrikel\\\\Jordstykke\\\\MAT_jordstykke_DK.shp'\n",
    "jordstykke_gdf = gpd.read_file(jordstykke_path)\n",
    "\n",
    "# Output directory\n",
    "output_dir = 'D:\\\\FOLDER FROM THESIS\\\\THESIS\\\\Processed data\\\\Jordstykke_municipalities'\n",
    "\n",
    "# Check if the output directory exists; if not, create it\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop through each unique 'kommunekod'\n",
    "for code in jordstykke_gdf['kommunekod'].unique():\n",
    "    # Filter the GeoDataFrame based on 'kommunekod'\n",
    "    subset_gdf = jordstykke_gdf[jordstykke_gdf['kommunekod'] == code]\n",
    "    \n",
    "    # Skip if no records are found for the current 'kommunekod'\n",
    "    if subset_gdf.empty:\n",
    "        print(f\"Skipping empty subset for kommunekod {code}\")\n",
    "        continue\n",
    "    \n",
    "    # Define the output path\n",
    "    output_path = os.path.join(output_dir, f\"{code}.shp\")\n",
    "    \n",
    "    # Save the subset GeoDataFrame to a new shapefile\n",
    "    subset_gdf.to_file(output_path, crs=\"EPSG:25832\")\n",
    "    \n",
    "    print(f\"Saved shapefile for kommunekod {code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b58bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script that merges VUR data for the 3 kinds of BFE-IDs by summing the values for EjendomværdiBeløb (e_value), \n",
    "#grundværdiBeløb (g_value) and count\n",
    "\n",
    "# Define directories\n",
    "folder1 = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\ejerBPFG_MUNI'\n",
    "folder2 = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\VUR_MAT_MUNI2'\n",
    "output_folder = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\SFE_EJER_BPFG_MUNI'\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each shapefile in folder1\n",
    "for filename in os.listdir(folder1):\n",
    "    if filename.endswith(\".shp\"):\n",
    "        filepath1 = os.path.join(folder1, filename)\n",
    "        filepath2 = os.path.join(folder2, filename)\n",
    "\n",
    "        # Read shapefiles\n",
    "        gdf1 = gpd.read_file(filepath1)\n",
    "        gdf2 = gpd.read_file(filepath2)\n",
    "\n",
    "        # Merge GeoDataFrames based on 'id.lokalId'\n",
    "        merged_gdf = gdf1.merge(gdf2[['id.lokalId', 'e_value', 'g_value', 'count']], on='id.lokalId', suffixes=('', '_new'))\n",
    "\n",
    "        # Sum the original and new columns\n",
    "        merged_gdf['e_value'] += merged_gdf['e_value_new']\n",
    "        merged_gdf['g_value'] += merged_gdf['g_value_new']\n",
    "        merged_gdf['count'] += merged_gdf['count_new']\n",
    "\n",
    "        # Keep only the desired columns and maintain as GeoDataFrame\n",
    "        final_gdf = gpd.GeoDataFrame(merged_gdf[['id.lokalId', 'e_value', 'g_value', 'count', 'geometry']], geometry='geometry')\n",
    "\n",
    "        # Save to new shapefile\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        final_gdf.to_file(output_path)\n",
    "        print(f\"Saved combined data to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "acffe9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory and output path\n",
    "input_folder = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\SFE_EJER_BPFG_MUNI'\n",
    "output_file = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\VUR_DK\\VUR_Total_DK.shp'\n",
    "\n",
    "# Create a list to store each processed GeoDataFrame\n",
    "all_gdfs = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.shp'):\n",
    "        filepath = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Read the shapefile into a GeoDataFrame\n",
    "        gdf = gpd.read_file(filepath)\n",
    "        \n",
    "        # Create a new 'building' field\n",
    "        gdf['building'] = gdf['e_value'] - gdf['g_value']\n",
    "        \n",
    "        # Create a new 'b_div_c' field\n",
    "        gdf['b_div_c'] = gdf['building'] / gdf['count']\n",
    "        \n",
    "        # Append to list of all GeoDataFrames\n",
    "        all_gdfs.append(gdf)\n",
    "\n",
    "# Concatenate all GeoDataFrames into one\n",
    "final_gdf = pd.concat(all_gdfs, ignore_index=True)\n",
    "\n",
    "# Convert it back to a GeoDataFrame if needed\n",
    "final_gdf = gpd.GeoDataFrame(final_gdf, geometry='geometry')\n",
    "\n",
    "# Save to new shapefile\n",
    "final_gdf.to_file(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d9fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
