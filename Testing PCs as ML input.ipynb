{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fcfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a collection og all scripts for testing PCs as ML input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a17605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path with the correct path to your .geojson file\n",
    "file_path = r'D:\\FOLDER FROM THESIS\\THESIS\\Processed data\\Training ML\\filled_manipulated_28_11.geojson'\n",
    "\n",
    "# Load the .geojson file into a GeoDataFrame\n",
    "gdf = gpd.read_file(file_path)\n",
    "\n",
    "with pd.option_context('display.max_columns', None, 'display.max_rows', None):\n",
    "    # Print the first 20 rows\n",
    "    print(\"First 20 rows:\")\n",
    "    print(gdf.head(20))\n",
    "\n",
    "    # Print the last 20 rows\n",
    "    print(\"\\nLast 20 rows:\")\n",
    "    print(gdf.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['byg032YdervæggensMateriale', 'byg033Tagdækningsmateriale', 'byg056Varmeinstallation', \n",
    "                       'eta006BygningensEtagebetegnelse', 'landscape', 'TSYM', 'byg021BygningensAnvendelse_grouped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48499405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant fields\n",
    "columns_to_drop = ['byg021BygningensAnvendelse', 'geometry', 'byg404Koordinat', 'byg406Koordinatsystem', 'x', 'y']\n",
    "gdf = gdf.drop(columns=columns_to_drop)\n",
    "\n",
    "gdf_reduced = pd.get_dummies(gdf, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric variables to be dropped\n",
    "coorelated_variables_to_drop = [\n",
    "    'maksimal5d', 'maksimal14', 'doegn10mm', 'doegn20mm', 'time2aarsh', 'time5aarsh', \n",
    "    'time10aars', 'time20aars', 'time50aars', 'time100aar', 'doegn5aars', 'doegn10aar', \n",
    "    'doegn20aar', 'doegn50aar', 'doegn100aa', 'toerredage', 'toerreperi', 'potentielf', \n",
    "    'solindstra', 'dagligmint', 'lavestetem', 'gennemsn_1', 'gennemsnit', 'varmeboelg', 'doegnetste', \n",
    "    'hedeboelge', 'hoejestete', 'vaekstsaes', 'ekstremvin', 'maksimaldo', 'skybrud', \n",
    "    'aaretstemp', 'e_value', 'g_value', 'count', 'building', 'clay_accu_', 'streamlake', 'sand_accu'\n",
    "]\n",
    "\n",
    "# Drop specified numeric variables and exclude non-numeric columns\n",
    "gdf_reduced_2 = gdf_reduced.drop(columns=coorelated_variables_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gdf_reduced = pd.get_dummies(gdf.drop(columns=['Damage']), columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_reduced)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "X = pca_result[:, :200]  # Select the first 200 PCs\n",
    "y = gdf['Damage']\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store overall evaluation metrics\n",
    "overall_metrics = []\n",
    "\n",
    "# Classification report for each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train the Random Forest Classifier\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=60,\n",
    "        min_samples_split=4,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    overall_metrics.append(report)\n",
    "    print(\"Classification Report for a fold:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e39c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "gdf_reduced = pd.get_dummies(gdf.drop(columns=['Damage']), columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_reduced)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "# Extract the first 200 PCs for the ML model\n",
    "X = pca_result[:, :200]\n",
    "y = gdf['Damage']\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "# Classification report for each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train the AdaBoostClassifier\n",
    "    ada_model = AdaBoostClassifier(\n",
    "        base_estimator=base_estimator,\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    )\n",
    "    ada_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred = ada_model.predict(X_test)\n",
    "    print(\"Classification Report for a fold:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e79a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "gdf_reduced = pd.get_dummies(gdf.drop(columns=['Damage']), columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_reduced)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "# Extract the first 200 PCs for the ML model\n",
    "X = pca_result[:, :200]\n",
    "y = gdf['Damage']\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Classification report for each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train the Gradient Boosting Classifier\n",
    "    gb_model = GradientBoostingClassifier(\n",
    "        n_estimators=900,\n",
    "        learning_rate=0.07333333333333333,\n",
    "        max_depth=8,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    gb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred = gb_model.predict(X_test)\n",
    "    print(\"Classification Report for a fold:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a20da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# One-Hot Encode Categorical Variables\n",
    "categorical_columns = ['byg032YdervæggensMateriale', 'byg033Tagdækningsmateriale', 'byg056Varmeinstallation', \n",
    "                       'eta006BygningensEtagebetegnelse', 'landscape', 'TSYM', 'byg021BygningensAnvendelse_grouped']\n",
    "gdf_encoded = pd.get_dummies(gdf, columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_encoded.drop(columns=['Damage']))\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "# Extract the first 200 PCs for the ML model\n",
    "X = pca_result[:, :200]\n",
    "y = gdf['Damage']\n",
    "\n",
    "# K-Fold Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    print('Training for fold', fold_no)\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=20, batch_size=128, verbose=0)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(X_test_fold, y_test_fold, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    fold_no += 1\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred_fold = (model.predict(X_test_fold) > 0.5).astype(\"int32\")\n",
    "    print(\"Classification Report for a fold:\\n\", classification_report(y_test_fold, y_pred_fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XG Boost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# One-Hot Encode Categorical Variables and exclude the 'Damage' variable\n",
    "categorical_columns = ['byg032YdervæggensMateriale', 'byg033Tagdækningsmateriale', 'byg056Varmeinstallation', \n",
    "                       'eta006BygningensEtagebetegnelse', 'landscape', 'TSYM', 'byg021BygningensAnvendelse_grouped']\n",
    "gdf_encoded = pd.get_dummies(gdf.drop(columns=['Damage']), columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_encoded)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "# Extract the first 200 PCs for the ML model\n",
    "X = pca_result[:, :200]\n",
    "y = gdf['Damage']\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Classification report for each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train the XGBClassifier\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.2,\n",
    "        max_depth=2,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.1,\n",
    "        gamma=0.2,\n",
    "        min_child_weight=6,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    print(\"Classification Report for a fold:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8521aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light GBM\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "gdf_reduced = pd.get_dummies(gdf.drop(columns=['Damage']), columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_reduced)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "# Extract the first 200 PCs for the ML model\n",
    "X = pca_result[:, :200]\n",
    "y = gdf['Damage']\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Classification report for each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train the LightGBM Classifier\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=250,\n",
    "        learning_rate=0.15,\n",
    "        max_depth=9,\n",
    "        num_leaves=100,\n",
    "        random_state=42\n",
    "    )\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "    print(\"Classification Report for a fold:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b47490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# One-Hot Encode Categorical Variables and exclude the 'Damage' variable\n",
    "categorical_columns = ['byg032YdervæggensMateriale', 'byg033Tagdækningsmateriale', 'byg056Varmeinstallation', \n",
    "                       'eta006BygningensEtagebetegnelse', 'landscape', 'TSYM', 'byg021BygningensAnvendelse_grouped']\n",
    "gdf_encoded = pd.get_dummies(gdf.drop(columns=['Damage']), columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_encoded)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "# Extract the first 200 PCs for the ML model\n",
    "X = pca_result[:, :200]\n",
    "y = gdf['Damage']\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Classification report for each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train the Gaussian Naive Bayes model\n",
    "    gnb_model = GaussianNB(var_smoothing=5.455594781168514e-06)\n",
    "    gnb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred = gnb_model.predict(X_test)\n",
    "    print(\"Classification Report for a fold:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48068ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "gdf_encoded = pd.get_dummies(gdf.drop(columns=['Damage']), columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_encoded)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "# Extract the first 200 PCs for the ML model\n",
    "X = pca_result[:, :200]\n",
    "y = gdf['Damage']\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Classification report for each fold\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and train the KNN Classifier\n",
    "    knn_model = KNeighborsClassifier(\n",
    "        n_neighbors=7,\n",
    "        weights='distance',\n",
    "        algorithm='ball_tree'\n",
    "    )\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    print(f\"Classification Report for fold {fold}:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(file_path)\n",
    "\n",
    "# Drop irrelevant fields and one-hot encode categorical variables\n",
    "columns_to_drop = ['byg021BygningensAnvendelse', 'geometry', 'byg404Koordinat', 'byg406Koordinatsystem', 'x', 'y']\n",
    "categorical_columns = ['byg032YdervæggensMateriale', 'byg033Tagdækningsmateriale', 'byg056Varmeinstallation', \n",
    "                       'eta006BygningensEtagebetegnelse', 'landscape', 'TSYM', 'byg021BygningensAnvendelse_grouped']\n",
    "gdf = gdf.drop(columns=columns_to_drop)\n",
    "gdf_encoded = pd.get_dummies(gdf, columns=categorical_columns)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "gdf_scaled = scaler.fit_transform(gdf_encoded.drop(columns=['Damage']))\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(gdf_scaled)\n",
    "\n",
    "# Extract the first 200 PCs for the ML model\n",
    "X = pca_result[:, :200]\n",
    "y = gdf['Damage']\n",
    "\n",
    "# Define the base learners\n",
    "base_learners = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('lgbm', LGBMClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gnb', GaussianNB())\n",
    "]\n",
    "\n",
    "# Define the final estimator\n",
    "final_estimator = RidgeClassifier()\n",
    "\n",
    "# Define the Stacking Classifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=base_learners, \n",
    "    final_estimator=final_estimator, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Classification report for each fold\n",
    "fold_no = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the stacked model\n",
    "    print('Training for fold', fold_no)\n",
    "    stacked_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Predictions and Evaluation\n",
    "    y_pred_fold = stacked_model.predict(X_test_fold)\n",
    "    print(f\"Classification Report for fold {fold_no}:\\n\", classification_report(y_test_fold, y_pred_fold))\n",
    "    fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37b1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
